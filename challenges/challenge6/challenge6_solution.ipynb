{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 6: Actions\n",
    "## Introduction\n",
    "\n",
    "In this part of the challenge you will add another agent to the solution.\n",
    "\n",
    "This time will be an agent that performs actions on behalf of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "import requests\n",
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from urllib.parse import quote_plus \n",
    "from its_a_rag import ingestion\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import AgentExecutor, create_sql_agent, create_openai_tools_agent\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Variables\n",
    "\n",
    "**Important:** Make sure you update your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv, sys\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "\n",
    "# Setup environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Local Folder for the documents\n",
    "LOCAL_FOLDER = \"D:\\fsi2023\"\n",
    "\n",
    "# SQL Database\n",
    "SQL_SERVER = os.getenv(\"SQL_SERVER\")\n",
    "SQL_DB = os.getenv(\"SQL_DB\")\n",
    "SQL_USERNAME = os.getenv(\"SQL_USERNAME\")\n",
    "SQL_PWD = os.getenv(\"SQL_PWD\")\n",
    "SQL_DRIVER = os.getenv(\"SQL_DRIVER\")\n",
    "\n",
    "# STOCK API\n",
    "MOCK_API_ENDPOINT= os.getenv(\"MOCK_API_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build on top of the previous solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(api_key = AZURE_OPENAI_API_KEY,  \n",
    "                      api_version = \"2024-06-01\",\n",
    "                      azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "                      model= AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                      streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Agent\n",
    "\n",
    "def stock_agent(state):\n",
    "    # Import the LLM\n",
    "    global llm\n",
    "    stock_agent_llm = llm\n",
    "    # Create the DB Connection\n",
    "    connection_string = f\"Driver={SQL_DRIVER};Server=tcp:{SQL_SERVER},1433;Database={SQL_DB};Uid={SQL_USERNAME};Pwd={SQL_PWD};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    quoted_conn_str = quote_plus(connection_string)\n",
    "    engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted_conn_str))\n",
    "    # Create the SQL Database Object and the SQL Database Toolkit Object to be used by the agent.\n",
    "    db = SQLDatabase(engine=engine)\n",
    "    stock_toolkit = SQLDatabaseToolkit(db=db, llm=stock_agent_llm)\n",
    "    # Create the agent using the Langhcain SQL Agent Class (create_sql_agent)\n",
    "    stock_agent = create_sql_agent(\n",
    "        toolkit=stock_toolkit,\n",
    "        llm=stock_agent_llm,\n",
    "        agent_type=\"openai-tools\",\n",
    "        agent_name=\"StockAgent\",\n",
    "        agent_description=\"Stock Agent\",\n",
    "        agent_version=\"0.1\",\n",
    "        agent_author=\"itsarag\",\n",
    "        #verbose=True,\n",
    "        agent_executor_kwargs=dict(handle_parsing_errors=True))\n",
    "    # Structure the final prompt from the ChatPromptTemplate\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \n",
    "            \"\"\"\n",
    "            You are a helpful AI assistant expert in querying SQL Database to find answers to user's question about stock prices. \\n\n",
    "            If you can't find the answer, say 'I am unable to find the answer.'\n",
    "            \"\"\"\n",
    "            ),\n",
    "            (\"user\", \"{question}\\n ai: \"),\n",
    "        ]\n",
    "    )\n",
    "    # Prepare the response using the invoke method of the agent\n",
    "    response = stock_agent.invoke(final_prompt.format(question=state[\"input\"]))\n",
    "    # Return the response for the next agent (output and input required coming fron the Agent State)\n",
    "    return {\"output\": response['output'], \"input\": state[\"input\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node rag (this is a clean implementation of the RAG Agent completed in Challenge 4)\n",
    "\n",
    "def rag_agent(state):\n",
    "    # Define the LLM\n",
    "    global llm\n",
    "    rag_agent_llm = llm\n",
    "    # Define the index (use the one created in the previous challenge - as the index is huge, we are using a top_k of 10)\n",
    "    retriever_multimodal = AzureAISearchRetriever(index_name=AZURE_SEARCH_INDEX, api_key=AZURE_SEARCH_API_KEY, service_name=AZURE_SEARCH_ENDPOINT, top_k=10)\n",
    "    # Define the chain (as it was in the previous challenge)\n",
    "    chain_multimodal_rag = (\n",
    "    {\n",
    "        \"context\": retriever_multimodal | RunnableLambda(ingestion.get_image_description),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(ingestion.multimodal_prompt)\n",
    "    | rag_agent_llm\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "    # prepare the response using the invoke method of the agent\n",
    "    response = chain_multimodal_rag.invoke({\"input\": state[\"input\"]})\n",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n",
    "    return {\"output\": response, \"input\": state[\"input\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Stock Action Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node stock_action\n",
    "# Define the tool using the @tool decorator\n",
    "@tool\n",
    "def buy_stocks(quantity: int, symbol: str) -> str:\n",
    "    '''Permit to acquire/buy a certain quantity of stocks of a certain company identified by its symbol'''\n",
    "    if not symbol or not quantity:\n",
    "        return f\"Missing required arguments: symbol and quantity are required.\"\n",
    "    try:\n",
    "        response = requests.post(f\"{MOCK_API_ENDPOINT}/api/buy/?stock_symbol={symbol}&quantity={quantity}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"message\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Failed to buy stock. Exception: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sell_stocks(quantity: int, symbol: str) -> str:\n",
    "    '''Permit to sell a certain quantity of stocks of a certain company identified by its symbol'''\n",
    "    if not symbol or not quantity:\n",
    "        return f\"Missing required arguments: symbol and quantity are required.\"\n",
    "    try:\n",
    "        response = requests.post(f\"{MOCK_API_ENDPOINT}/api/sell/?stock_symbol={symbol}&quantity={quantity}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"message\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Failed to sell stock. Exception: {str(e)}\"\n",
    "\n",
    "\n",
    "# you can combine multiple tools in a single block called Toolkit\n",
    "stock_toolkit = [buy_stocks, sell_stocks]\n",
    "\n",
    "def stock_action(state):\n",
    "    # Define the LLM\n",
    "    global llm\n",
    "    stock_action_llm = llm\n",
    "    # Prepare the prompt for the agent (the create_openai_tools_agent function requires a ChatPromptTemplate object)\n",
    "    # Prompt Example: \"You are an agent that helps to acquire stocks. Use your tools to perform the requested action. \\n if you can't perform the action, say 'I am unable to perform the action.' \\n\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \n",
    "            \"\"\"\n",
    "            You are an agent that helps to acquire stocks. Use your tools to perform the requested action. \\n\n",
    "            If you can't perform the action, say 'I am unable to perform the action.'\n",
    "            \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "            (\"human\", \"{input}\"),\n",
    "            MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    # Construct the OpenAI Tools Agent\n",
    "    stock_buyer = create_openai_tools_agent(stock_action_llm, stock_toolkit, prompt)\n",
    "    # Prepare the Agent Executor\n",
    "    stock_buyer_executor = AgentExecutor(agent=stock_buyer, tools=stock_toolkit)\n",
    "    # prepare the response using the invoke method of the agent\n",
    "    response = stock_buyer_executor.invoke({\"input\": state[\"input\"]})\n",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n",
    "    return {\"output\": response['output'], \"input\": state[\"input\"]}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Update the Start Agent adding an addition decision answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the start_agent that analyze the user question and decide if the question is related to stock prices or financial results\n",
    "def start_agent(state):\n",
    "    # Import the global llm\n",
    "    global llm\n",
    "    start_agent_llm = llm\n",
    "    # Prepare the prompt for the agent\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    You are an agent that needs analyze the user question. \\n\n",
    "    Question : {input} \\n\n",
    "    if the question is related to stock prices answer with \"stock\". \\n\n",
    "    if the question is related to stock sbuy/sell answer with \"stock_action\". \\n\n",
    "    if the question is related to information about financial results answer with \"rag\". \\n\n",
    "    if the question is unclear or you cannot decide answer with \"rag\". \\n\n",
    "    only answer with one of the word provided.\n",
    "    Your answer (stock/sotck_action/rag):\n",
    "    \"\"\")\n",
    "    # Prepare the chain to be executed\n",
    "    chain = prompt | start_agent_llm\n",
    "    # invoke the chain\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "    # take the decision from the response\n",
    "    decision = response.content.strip().lower()\n",
    "    # Return the response for the next agent (decision and input required coming fron the Agent State)\n",
    "    return {\"decision\": decision, \"input\": state[\"input\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update the previous graph to include the new agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "# this should include the input, output and decision as strings\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "\n",
    "# Create the 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "# Add nodes (start_agent, stock_agent, rag_agent) and conditional edges where the decision with be stock or rag\n",
    "def create_graph():\n",
    "    # Create the Workflow as StateGraph using the AgentState\n",
    "    workflow = StateGraph(AgentState)\n",
    "    # Add the nodes (start_agent, stock_agent, rag_agent)\n",
    "    workflow.add_node(\"start\", start_agent)\n",
    "    workflow.add_node(\"stock_agent\", stock_agent)\n",
    "    workflow.add_node(\"rag_agent\", rag_agent)\n",
    "    workflow.add_node(\"stock_action\", stock_action)\n",
    "    # Add the conditional edge from start -> lamba (decision) -> stock_agent or rag_agent\n",
    "    workflow.add_conditional_edges(\n",
    "        \"start\",\n",
    "        lambda x: x[\"decision\"],\n",
    "        {\n",
    "            \"stock\": \"stock_agent\",\n",
    "            \"rag\": \"rag_agent\",\n",
    "            \"stock_action\": \"stock_action\"\n",
    "        }\n",
    "    )\n",
    "    # Set the workflow entry point\n",
    "    workflow.set_entry_point(\"start\")\n",
    "    # Add the final edges to the END node\n",
    "    workflow.add_edge(\"stock_agent\", END)\n",
    "    workflow.add_edge(\"rag_agent\", END)\n",
    "    workflow.add_edge(\"stock_action\", END)\n",
    "    #Compile the workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Test the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Solution\n",
    "\n",
    "# intantiate the graph (create_graph)\n",
    "graph = create_graph()\n",
    "\n",
    "# Use the graph invoke to answer the questions\n",
    "\n",
    "# Question 1\n",
    "question = \"What was the price of Apple,Nvidia and Microsoft stocks in 23/07/2024?\"\n",
    "result = graph.invoke({\"input\": question})\n",
    "print(result[\"output\"])\n",
    "\n",
    "# Question 2\n",
    "question = \"Can you buy for me 100 stocks of MSFT?\"\n",
    "result = graph.invoke({\"input\": question})\n",
    "print(result[\"output\"])\n",
    "\n",
    "# Question 3\n",
    "question = \"What is the value of the cumulative 5-years total return of Alphabet Class A stock at December 2022?\"\n",
    "result = graph.invoke({\"input\": question})\n",
    "print(result[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
