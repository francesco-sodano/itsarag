{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Advanced RAG with Azure AI Document intelligence\n",
    "\n",
    "Many documents in  real scenario, are not just text, they are a combination of text, images, tables, etc. In this step, you will create a more advanced RAG application able to deal with this kind of documents.\n",
    "For this reason, you will use Azure AI Document Intelligence to extract the text, images, and tables from the documents and use them as input for the RAG model.\n",
    "\n",
    "To achieve this, we will build on top of the langchain framework enhancing the `Document Loader` and `Text Splitters` to deal with images and tables.\n",
    "In the code repositiory, you have already the enhanced version of the `Document Loader` and `Text Splitters` that you can use. They are included in two different python modules: `document_loader.py` and `text_splitters.py`.\n",
    "\n",
    "You can now use these libraries to create your advanced RAG.\n",
    "\n",
    "We provided already the libraries and the Environment variables required (you need just to populate them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, dotenv\n",
    "dotenv.load_dotenv()\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "# Setup environment\n",
    "\n",
    "# OpenAI\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "\n",
    "# Custom Libraries\n",
    "from its_a_rag.doc_intelligence import AzureAIDocumentIntelligenceLoader\n",
    "from its_a_rag import ingestion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vector store, the embeddings client and the OpenAI Chat client\n",
    "\n",
    "Let's start creating the vector store and the embeddings client. Because we need a custom index to store the information in the way so that our retriever wil be able to get it, we have a custom function for that (create_multimodal_vectore_store).\n",
    "For the OpenAI Chat client we will simply use the one offered by langchain framework as in the Step 3 of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index for Azure Search store and Embedding\n",
    "vector_store_multimodal, aoai_embeddings = ingestion.create_multimodal_vector_store(AZURE_SEARCH_INDEX, \n",
    "                                                                           AZURE_OPENAI_API_KEY, \n",
    "                                                                           AZURE_OPENAI_ENDPOINT,\n",
    "                                                                           AZURE_OPENAI_API_VERSION,\n",
    "                                                                           AZURE_OPENAI_EMBEDDING, \n",
    "                                                                           AZURE_SEARCH_ENDPOINT, \n",
    "                                                                           AZURE_SEARCH_API_KEY)\n",
    "\n",
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(api_key = AZURE_OPENAI_API_KEY,  \n",
    "                      api_version = \"2024-06-01\",\n",
    "                      azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "                      model= AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                      streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Phase\n",
    "\n",
    "As always the first step is to index the documents:\n",
    "the high level steps are:\n",
    "\n",
    "- Set Folder Path: Assign the local folder path to the variable folder.\n",
    "- List Files: Create a list of files in the specified folder.\n",
    "- Get Full Paths: Convert the list of file names to their full paths.\n",
    "- Iterate Over Files: Loop through each file in the list.\n",
    "    - Extract File Name: Extract the file name from the full path (this is required for the document loader).\n",
    "    - Load Document: Use AzureAIDocumentIntelligenceLoader to load the document with specified API credentials and settings (remember to use pre-built layout as model and the latest API version)\n",
    "    - Split Document: Split the loaded document using a custom advanced text splitter.\n",
    "    - Store Document: Add the processed documents to a multimodal vector store (using the add_documents method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY AMZN.pdf', '/workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY APPL.pdf', '/workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY GOOGL.pdf', '/workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY MSFT.pdf', '/workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY NVDA.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get list of files in a local folder\n",
    "folder = os.path.join(os.getcwd(), '../../../its-a-rag/data/fsi/pdf') # TODO: FIX ME\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(\"2023\")]\n",
    "files = [os.path.join(folder, f) for f in files]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  /workspaces/ch-hackathons/its-a-rag-solutions/challenges/challenge4/../../../its-a-rag/data/fsi/pdf/2023 FY AMZN.pdf\n"
     ]
    },
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(404) Resource not found\nCode: 404\nMessage: Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing: \u001b[39m\u001b[38;5;124m\"\u001b[39m, file)\n\u001b[1;32m     16\u001b[0m loader \u001b[38;5;241m=\u001b[39m AzureAIDocumentIntelligenceLoader(file_path\u001b[38;5;241m=\u001b[39mfile, \n\u001b[1;32m     17\u001b[0m                                        api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m822fb076b87d4f86b211a568d63ed1df\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     18\u001b[0m                                        api_endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docint-kbbxgc.cognitiveservices.azure.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m                                        api_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprebuilt-layout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m                                        api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-10-01\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                        analysis_features \u001b[38;5;241m=\u001b[39m [DocumentAnalysisFeature\u001b[38;5;241m.\u001b[39mOCR_HIGH_RESOLUTION])\n\u001b[0;32m---> 22\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Index : Split\u001b[39;00m\n\u001b[1;32m     24\u001b[0m docs \u001b[38;5;241m=\u001b[39m ingestion\u001b[38;5;241m.\u001b[39madvanced_text_splitter(docs,pdf_file_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ch-hackathons/its-a-rag-solutions/lib/its_a_rag/doc_intelligence.py:359\u001b[0m, in \u001b[0;36mAzureAIDocumentIntelligenceLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lazy load given path as pages.\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly local path is supported for now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:127\u001b[0m, in \u001b[0;36mBaseBlobParser.parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, blob: Blob) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Eagerly parse the blob into a document or documents.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    This is a convenience method for interactive development environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m        List of documents\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ch-hackathons/its-a-rag-solutions/lib/its_a_rag/doc_intelligence.py:311\u001b[0m, in \u001b[0;36mAzureAIDocumentIntelligenceParser.lazy_parse\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    309\u001b[0m blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(file_path)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mas_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[0;32m--> 311\u001b[0m     poller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/octet-stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_content_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarkdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarkdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_patch.py:537\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, analyze_request, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m cont_token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuation_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_document_initial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_content_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_content_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     raw_result\u001b[38;5;241m.\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    554\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_operations.py:713\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin._analyze_document_initial\u001b[0;34m(self, model_id, analyze_request, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (StreamConsumedError, StreamClosedError):\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m error \u001b[38;5;241m=\u001b[39m _deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/core/exceptions.py:161\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    160\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: (404) Resource not found\nCode: 404\nMessage: Resource not found"
     ]
    }
   ],
   "source": [
    "# Index\n",
    "\n",
    "# Index: Load files\n",
    "\n",
    "# Get list of files in a local folder\n",
    "folder = os.path.join(os.getcwd(), '../../../its-a-rag/data/fsi/pdf') # TODO: FIX ME\n",
    "files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(\"2023\")]\n",
    "files = [os.path.join(folder, f) for f in files]\n",
    "\n",
    "# For each file\n",
    "for file in files:\n",
    "    # Get the file name\n",
    "    pdf_file_name = file.split(\"\\\\\")[-1]\n",
    "    # Index : Load the file and create a document\n",
    "    print(\"Processing: \", file)\n",
    "    loader = AzureAIDocumentIntelligenceLoader(file_path=file, \n",
    "                                           api_key = \"822fb076b87d4f86b211a568d63ed1df\", \n",
    "                                           api_endpoint = \"https://docint-kbbxgc.cognitiveservices.azure.com/\",\n",
    "                                           api_model=\"prebuilt-layout\",\n",
    "                                           api_version=\"2024-10-01\",\n",
    "                                           analysis_features = [DocumentAnalysisFeature.OCR_HIGH_RESOLUTION])\n",
    "    docs = loader.load()\n",
    "    # Index : Split\n",
    "    docs = ingestion.advanced_text_splitter(docs,pdf_file_name)\n",
    "    # Index : Store\n",
    "    vector_store_multimodal.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(404) Resource not found\nCode: 404\nMessage: Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ch-hackathons/its-a-rag-solutions/lib/its_a_rag/doc_intelligence.py:359\u001b[0m, in \u001b[0;36mAzureAIDocumentIntelligenceLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lazy load given path as pages.\"\"\"\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly local path is supported for now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:127\u001b[0m, in \u001b[0;36mBaseBlobParser.parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, blob: Blob) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Eagerly parse the blob into a document or documents.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    This is a convenience method for interactive development environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m        List of documents\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ch-hackathons/its-a-rag-solutions/lib/its_a_rag/doc_intelligence.py:311\u001b[0m, in \u001b[0;36mAzureAIDocumentIntelligenceParser.lazy_parse\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    309\u001b[0m blob \u001b[38;5;241m=\u001b[39m Blob\u001b[38;5;241m.\u001b[39mfrom_path(file_path)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m blob\u001b[38;5;241m.\u001b[39mas_bytes_io() \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[0;32m--> 311\u001b[0m     poller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_analyze_document\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/octet-stream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_content_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarkdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarkdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     result \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_patch.py:537\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, analyze_request, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m cont_token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuation_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_document_initial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43manalyze_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manalyze_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstring_index_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_index_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_content_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_content_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     raw_result\u001b[38;5;241m.\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    554\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_operations.py:713\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin._analyze_document_initial\u001b[0;34m(self, model_id, analyze_request, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (StreamConsumedError, StreamClosedError):\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m error \u001b[38;5;241m=\u001b[39m _deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/azure/core/exceptions.py:161\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    160\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: (404) Resource not found\nCode: 404\nMessage: Resource not found"
     ]
    }
   ],
   "source": [
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Phase\n",
    "\n",
    "The next step is to create a retriever for the documents based on the user query.\n",
    "You should use the following parameters:\n",
    "- Search Type: Hybrid\n",
    "- number of results: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "retriever_multimodal = vector_store_multimodal.as_retriever(search_type=\"hybrid\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Phase\n",
    "\n",
    "The final step is to generate the answer using the RAG model.\n",
    "We will create a Langchain chain with the following steps:\n",
    " - Retrieve the docs and get the image desciption if the doc matedata is an image (with get_image_description function - RunnableLambda), then pass the context and question (using RunnablePassthrough) to the next phase\n",
    " - Use the advanced multimodal Prompt function to append system messages, the context including the text, the image (if present) and the question - check RannableLambda method also here.\n",
    " - Use the OpenAI model to generate the answer\n",
    " - Parse the output and return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "\n",
    "# RAG pipeline\n",
    "chain_multimodal_rag = (\n",
    "    {\n",
    "        \"context\": retriever_multimodal | RunnableLambda(ingestion.get_image_description),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | RunnableLambda(ingestion.multimodal_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Solution\n",
    "\n",
    "You can test the solution by providing a question and checking the answer generated by the RAG model (invoke the Langchain chain).\n",
    "\n",
    "Try to get answer for the following questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Intel in 2023:\n",
      "\n",
      "- **GAAP Gross Margin**: 40.0%\n",
      "- **Non-GAAP Gross Margin**: 43.6%\n",
      "\n",
      "**Detailed Breakdown:**\n",
      "\n",
      "| Measure                       | 2023      |\n",
      "|-------------------------------|-----------|\n",
      "| GAAP Gross Margin             | 40.0%     |\n",
      "| Non-GAAP Gross Margin         | 43.6%     |\n",
      "\n",
      "The GAAP gross margin decreased by 2.6 percentage points from 2022, and the Non-GAAP gross margin decreased by 3.7 percentage points from 2022.\n",
      "I don't know.\n",
      "In 2022, Intel's net revenue was $63,054 million, and the operating income was $2,334 million with an operating margin of 3.7%. \n",
      "\n",
      "Comparing it to 2021, the net revenue was $79,024 million, and the operating income was $19,456 million with an operating margin of 24.6%. \n",
      "\n",
      "Here's a concise comparison:\n",
      "\n",
      "| Year | Net Revenue (in millions) | Operating Income (in millions) | Operating Margin (%) |\n",
      "|------|----------------------------|-------------------------------|----------------------|\n",
      "| 2022 | $63,054                   | $2,334                        | 3.7%                 |\n",
      "| 2021 | $79,024                   | $19,456                       | 24.6%                |\n",
      "\n",
      "The revenue and operating income decreased significantly in 2022 compared to 2021.\n",
      "Based on the provided context, I can extract and create the following table comparing Intel's revenue from 2019 to 2023:\n",
      "\n",
      "| Year | Revenue (in billions) |\n",
      "|------|-----------------------|\n",
      "| 2019 | $71.97                |\n",
      "| 2020 | $77.87                |\n",
      "| 2021 | $79.0                 |\n",
      "| 2022 | $63.1                 |\n",
      "| 2023 | $54.2                 |\n",
      "\n",
      "Note: The revenue figures for 2019 and 2020 are assumed based on typical trends and may not be accurate. Please verify these from a reliable source.\n"
     ]
    }
   ],
   "source": [
    "# Test the solution\n",
    "print(chain_multimodal_rag.invoke(\"For intel, what is the GAAP and Non-GAAP for 2023 in percentage?\"))\n",
    "print(chain_multimodal_rag.invoke(\"What are the revenues of INTEL Comporation in the year 2000?\"))\n",
    "print(chain_multimodal_rag.invoke(\"What are the revenues and the operative margins of INTEL in 2022 and how it compares with the previous year?\"))\n",
    "print(chain_multimodal_rag.invoke(\"Can you compare and create a table with the revenue of INTEL in years 2019-2023?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
