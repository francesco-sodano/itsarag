{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5: Multi-Source, Multi-Agent\n",
    "## Introduction\n",
    "\n",
    "In this part of the challenge you will add another source of data (structured) to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Variables\n",
    "\n",
    "**Important:** Make sure you update your `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv,sys\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "\n",
    "# Setup environment\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_EMBEDDING\")\n",
    "# Azure Search\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "AZURE_SEARCH_INDEX = os.getenv(\"AZURE_SEARCH_INDEX\")\n",
    "# Azure AI Document Intelligence\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\")\n",
    "# Azure Blob Storage\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONTAINER = os.getenv(\"AZURE_STORAGE_CONTAINER\")\n",
    "AZURE_STORAGE_FOLDER = os.getenv(\"AZURE_STORAGE_FOLDER\")\n",
    "\n",
    "# Local Folder for the documents\n",
    "LOCAL_FOLDER = \"D:\\fsi2023\"\n",
    "\n",
    "# SQL Database\n",
    "SQL_SERVER = os.getenv(\"SQL_SERVER\")\n",
    "SQL_DB = os.getenv(\"SQL_DB\")\n",
    "SQL_USERNAME = os.getenv(\"SQL_USERNAME\")\n",
    "SQL_PWD = os.getenv(\"SQL_PWD\")\n",
    "SQL_DRIVER = os.getenv(\"SQL_DRIVER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Sure you have the ODBC driver installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the installed ODBC drivers (you should have installed the \"ODBC Driver 18 for SQL Server\")\n",
    "import pyodbc\n",
    "\n",
    "print(pyodbc.drivers())\n",
    "assert os.getenv('SQL_DRIVER') in pyodbc.drivers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import data to the SQL Database\n",
    "\n",
    "The database provided is an Azure SQL Database.\n",
    "Upload the data to the SQL Database using the `./data/fsi/db/create_stock_table.sql` script.\n",
    "\n",
    "The script will create a table named \"stock\" in the provided database.\n",
    "The table contains the following columns:\n",
    "- **Date** DATE\n",
    "- **CloseLast** DECIMAL(10, 2) \n",
    "- **Volume** INT\n",
    "- **Open** DECIMAL(10, 2)\n",
    "- **High** DECIMAL(10, 2)\n",
    "- **Low** DECIMAL(10, 2)\n",
    "- **Symbol** VARCHAR(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Connection to the SQL Server Database (sqlalchemy)\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "connection_string = f\"Driver={SQL_DRIVER};Server=tcp:{SQL_SERVER},1433;Database={SQL_DB};Uid={SQL_USERNAME};Pwd={SQL_PWD};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "quoted_conn_str = quote_plus(connection_string)\n",
    "# Create the sqlalchemy engine (mssql+pyodbc)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted_conn_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Stock Table in the SQL Server Database\n",
    "with open('../../data/fsi/db/create_stock_table.sql', 'r') as file:\n",
    "    sql_statements = file.read()\n",
    "\n",
    "# Execute the SQL Statements\n",
    "with engine.connect() as connection:\n",
    "    for command in sql_statements.split('GO'):\n",
    "        command = command.strip()\n",
    "        if command:\n",
    "            connection.execute(text(command))\n",
    "    connection.execute(text(\"commit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a LangChain SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI Chat Client\n",
    "llm = AzureChatOpenAI(api_key = AZURE_OPENAI_API_KEY,  \n",
    "                      api_version = \"2024-06-01\",\n",
    "                      azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "                      model= AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "                      streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LangChain SQL Database Object and the SQL Database Toolkit Object to be used by the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stock_agent using the Langhcain SQL Agent Class (create_sql_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure the final prompt from the ChatPromptTemplate\n",
    "# include the system message to the user message\n",
    "# System message: You are a helpful AI assistant expert in querying SQL Database to find answers to user's question about stock prices. If you can't find the answer, say 'I am unable to find the answer.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create the Multi Agent Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../lib')))\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "from typing import Annotated, Sequence\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph import StateGraph, END\n",
    "from urllib.parse import quote_plus \n",
    "from its_a_rag import ingestion\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI Chat Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the start_agent that analyze the user question and decide if the question is related to stock prices or financial results\n",
    "def start_agent(state):\n",
    "    # Import the global llm\n",
    "\n",
    "    # Prepare the prompt for the agent\n",
    "    # Prompt Example: You are an agent that needs analyze the user question. \\n Question : {input} \\n if the question is related to stock prices answer with \"stock\". \\n if the question is related to information about financial results answer with \"rag\". \\n if the question is unclear or you cannot decide answer with \"rag\". \\n only answer with one of the word provided. Your answer (stock/rag):\n",
    "\n",
    "    # Prepare the chain to be executed\n",
    "\n",
    "    # invoke the chain\n",
    "\n",
    "    # take the decision from the response\n",
    "\n",
    "    # Return the response for the next agent (decision and input required coming fron the Agent State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Agent\n",
    "\n",
    "def stock_agent(state):\n",
    "    # Import the LLM\n",
    "\n",
    "    # Create the DB Connection\n",
    "\n",
    "    # Create the SQL Database Object and the SQL Database Toolkit Object to be used by the agent.\n",
    "\n",
    "    # Create the agent using the Langhcain SQL Agent Class (create_sql_agent)\n",
    "\n",
    "    # Structure the final prompt from the ChatPromptTemplate\n",
    "\n",
    "    # Prepare the response using the invoke method of the agent\n",
    "\n",
    "    # Return the response for the next agent (output and input required coming fron the Agent State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node rag (this is a clean implementation of the RAG Agent completed in Challenge 4)\n",
    "\n",
    "def rag_agent(state):\n",
    "    # Define the LLM\n",
    "\n",
    "    # Define the index (use the one created in the previous challenge)\n",
    "\n",
    "    # Define the chain (as it was in the previous challenge)\n",
    "\n",
    "    # prepare the response using the invoke method of the agent\n",
    "\n",
    "    # Return the response for the next agent (output and input required coming from the Agent State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent State Class to store the messages between the agents\n",
    "# this should include the input, output and decision as strings\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "\n",
    "# Create the 3 steps graph that is going to be working in the bellow \"decision\" condition\n",
    "# Add nodes (start_agent, stock_agent, rag_agent) and conditional edges where the decision with be stock or rag\n",
    "def create_graph():\n",
    "    # Create the Workflow as StateGraph using the AgentState\n",
    "\n",
    "    # Add the nodes (start_agent, stock_agent, rag_agent)\n",
    "\n",
    "    # Add the conditional edge from start -> lamba (decision) -> stock_agent or rag_agent\n",
    "\n",
    "    # Set the workflow entry point\n",
    "\n",
    "    # Add the final edges to the END node\n",
    "\n",
    "    #Compile the workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Solution\n",
    "\n",
    "# intantiate the graph (create_graph)\n",
    "graph = create_graph()\n",
    "\n",
    "# Use the graph invoke to answer the questions\n",
    "# Test the graph with various questions\n",
    "questions = [\n",
    "    \"What are the revenues of Google in the year 2000?\",\n",
    "    \"What are the revenues and the operative margins of Alphabet Inc. in 2022 and how it compares with the previous year?\",\n",
    "    \"Can you compare and create a table with the revenue of Alphabet Inc., NVIDIA, MICROSOFT, APPLE and AMAZON in years 2023?\",\n",
    "    \"Did APPLE repurchase common stock in 2023? create a table of Apple repurchased stock with date, numbers of stocks and values in dollars.\",\n",
    "    \"Can you give me the Fiscal Year 2023 Highlights for Apple, Microsoft, Nvidia and Google?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = graph.invoke({\"input\": question})\n",
    "    print(result[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
